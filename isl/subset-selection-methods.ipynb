{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9ca13d85-a7d0-4e4c-b3a2-e3d1a4431178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "256f85bc-2faf-482a-86de-6b910a7739a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Hitters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6061209e-9e52-4ecf-80df-f47f0ff711dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?', np.nan) # assume ? is na value\n",
    "full_df = df # df without dropped values, bad stuff should only in salary\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "adea374b-fff1-4c83-b408-53bbba1cf07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_328/3731035747.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, [q]] = df[q].map({key: index for index, key in enumerate(vals)})\n",
      "/tmp/ipykernel_328/3731035747.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, [q]] = df[q].map({key: index for index, key in enumerate(vals)})\n",
      "/tmp/ipykernel_328/3731035747.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, [q]] = df[q].map({key: index for index, key in enumerate(vals)})\n"
     ]
    }
   ],
   "source": [
    "qual = ['League', 'Division', 'NewLeague']\n",
    "\n",
    "for q in qual:\n",
    "    vals = df[q].unique()\n",
    "    df.loc[:, [q]] = df[q].map({key: index for index, key in enumerate(vals)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "626dc0d4-29bd-413b-9f09-e99017a80d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "50d34f33-137e-47ce-9e0c-ca2371ffd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Salary']\n",
    "x = df.drop(['Salary'], axis=1).astype('float64')\n",
    "# set the variables you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4759eaec-656e-4725-9a86-c4330b8bf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset selection, don't run this it'll take forever\n",
    "def calc_subset(feature_set, x, y):\n",
    "    data = x[list(feature_set)]\n",
    "    data = sm.add_constant(data)\n",
    "    model = sm.OLS(y, data)\n",
    "    result = model.fit()\n",
    "    residuals = y - result.predict(data)\n",
    "    error = (residuals * residuals).sum()\n",
    "    return {'model': result, 'features': list(feature_set), 'rss': error}\n",
    "\n",
    "def split(a, n): # if i were using processes, i could split using this\n",
    "    k, m = divmod(len(a), n)\n",
    "    return list(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "def enumerate_subsets(k, x, y, threads=1): # enumerate subsets of size k (Gosper's hack can work, but we use itertools)\n",
    "    print(f'calculating for subsets of size {k}')\n",
    "    \n",
    "    start = time.time()\n",
    "    combos = list(itertools.combinations(x.columns, k))\n",
    "    \n",
    "    # multiprocessing fails in jupyter\n",
    "    # pool = Pool(processes=3)\n",
    "    # results = pool.map(calc_subset, combos)\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "    \n",
    "    results = []\n",
    "    for c in combos:\n",
    "        results.append(calc_subset(c, x, y))\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(f'done with size {k}, took {elapsed} seconds')\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best = results_df.loc[results_df['rss'].argmin()]\n",
    "    return dict(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "956979ac-a217-440f-adcd-ccce4f52f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating for subsets of size 1\n",
      "done with size 1, took 0.038878440856933594 seconds\n",
      "calculating for subsets of size 2\n",
      "done with size 2, took 0.3381383419036865 seconds\n",
      "calculating for subsets of size 3\n",
      "done with size 3, took 1.9585189819335938 seconds\n"
     ]
    }
   ],
   "source": [
    "features = len(x.columns)\n",
    "features = min(features, 3) # otherwise we take too long\n",
    "subset_selection = {i: enumerate_subsets(i, x, y) for i in range(1, features + 1)}\n",
    "# i'm skipping the plotting too, because this takes forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "536e9699-b83a-4323-a877-3c40b957ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwards_stepwise(predictors, x, y):\n",
    "    remaining = [p for p in x.columns if p not in predictors]\n",
    "    results = []\n",
    "    for p in remaining:\n",
    "        results.append(calc_subset(predictors + [p], x, y))\n",
    "    models = pd.DataFrame(results)\n",
    "    best_model = models.loc[models['rss'].argmin()]\n",
    "    return dict(best_model)\n",
    "\n",
    "def backwards_stepwise(predictors, x, y):\n",
    "    results = []\n",
    "    for combo in itertools.combinations(predictors, len(predictors) - 1):\n",
    "        results.append(calc_subset(combo, x, y))\n",
    "    models = pd.DataFrame(results)\n",
    "    best_model = models.loc[models['rss'].argmin()]\n",
    "    return dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8d5ebfae-834a-4712-a8e2-020749ef3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y):\n",
    "    models_fwd = pd.DataFrame(columns=['rss', 'model'])\n",
    "\n",
    "    predictors = []\n",
    "\n",
    "    for i in range(1, len(x.columns) + 1):\n",
    "        models_fwd.loc[i] = forwards_stepwise(predictors, x, y)\n",
    "        predictors = models_fwd.loc[i]['model'].model.exog_names.copy()\n",
    "        predictors.remove('const')\n",
    "    \n",
    "    return models_fwd\n",
    "\n",
    "def backward(x, y):\n",
    "    models_bwd = pd.DataFrame(columns=['rss', 'model'])\n",
    "\n",
    "    predictors = x.columns\n",
    "    while(len(predictors) > 1):  \n",
    "        models_bwd.loc[len(predictors) - 1] = backwards_stepwise(predictors, x, y)\n",
    "        predictors = models_bwd.loc[len(predictors) - 1]['model'].model.exog_names.copy()\n",
    "        predictors.remove('const')\n",
    "    \n",
    "    return models_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6f695b4c-8297-4142-a650-4cd03dd13fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Salary   R-squared:                       0.513\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     38.41\n",
      "Date:                Mon, 25 Jul 2022   Prob (F-statistic):           1.50e-36\n",
      "Time:                        20:00:16   Log-Likelihood:                -1885.4\n",
      "No. Observations:                 263   AIC:                             3787.\n",
      "Df Residuals:                     255   BIC:                             3815.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -17.3351     64.535     -0.269      0.788    -144.424     109.754\n",
      "CRBI           0.8538      0.151      5.640      0.000       0.556       1.152\n",
      "Hits           7.4499      1.661      4.485      0.000       4.179      10.721\n",
      "PutOuts        0.2533      0.075      3.382      0.001       0.106       0.401\n",
      "Division     127.1224     39.807      3.193      0.002      48.730     205.515\n",
      "AtBat         -1.9589      0.529     -3.701      0.000      -3.001      -0.917\n",
      "Walks          4.9131      1.443      3.405      0.001       2.072       7.755\n",
      "CWalks        -0.3053      0.199     -1.538      0.125      -0.696       0.086\n",
      "==============================================================================\n",
      "Omnibus:                      102.245   Durbin-Watson:                   1.988\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              609.074\n",
      "Skew:                           1.434   Prob(JB):                    5.51e-133\n",
      "Kurtosis:                       9.882   Cond. No.                     2.51e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.51e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "---------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Salary   R-squared:                       0.514\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     38.47\n",
      "Date:                Mon, 25 Jul 2022   Prob (F-statistic):           1.35e-36\n",
      "Time:                        20:00:16   Log-Likelihood:                -1885.3\n",
      "No. Observations:                 263   AIC:                             3787.\n",
      "Df Residuals:                     255   BIC:                             3815.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.5205     64.607     -0.163      0.871    -137.752     116.711\n",
      "AtBat         -1.9763      0.529     -3.733      0.000      -3.019      -0.934\n",
      "Hits           6.7575      1.674      4.037      0.000       3.461      10.054\n",
      "Walks          6.0559      1.536      3.943      0.000       3.031       9.081\n",
      "CRuns          1.1293      0.199      5.661      0.000       0.736       1.522\n",
      "CWalks        -0.7163      0.265     -2.699      0.007      -1.239      -0.194\n",
      "Division     116.1692     39.713      2.925      0.004      37.961     194.377\n",
      "PutOuts        0.3029      0.075      4.058      0.000       0.156       0.450\n",
      "==============================================================================\n",
      "Omnibus:                      103.266   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              610.419\n",
      "Skew:                           1.454   Prob(JB):                    2.81e-133\n",
      "Kurtosis:                       9.873   Cond. No.                     2.57e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.57e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "models_fwd = forward(x, y)\n",
    "models_bwd = backward(x, y)\n",
    "\n",
    "print(models_fwd.loc[7]['model'].summary())\n",
    "print('---------------')\n",
    "print(models_bwd.loc[7]['model'].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f220740c-aaed-4bb7-b5a7-79d0823b37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks\n",
    "train_mask = np.full(len(x), True) \n",
    "train_mask[len(x) // 2:len(x)] = False\n",
    "np.random.shuffle(train_mask)\n",
    "test_mask = np.logical_not(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3bd227cb-15c3-4284-a05b-6d31db2374a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "x_train = x[train_mask] \n",
    "y_train = y[train_mask]\n",
    "x_test = x[test_mask]\n",
    "y_test = y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "af156f7f-6685-4212-a0f6-235cfbb3d9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rss</th>\n",
       "      <th>model</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.903192e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.798528e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.706033e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.534800e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.621585e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.529801e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.551892e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.656181e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.497127e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.585112e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.463724e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.685786e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.405633e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.541311e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.364427e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.734648e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.315073e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.771516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.268189e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.655227e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.232436e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.718486e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.216791e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.771235e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.204376e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.711102e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.188522e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.723682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.174204e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.730748e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.167980e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.721915e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.166015e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.734628e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.165803e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.740698e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.165779e+07</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>1.739717e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rss                                              model  \\\n",
       "1   1.903192e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "2   1.706033e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "3   1.621585e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "4   1.551892e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "5   1.497127e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "6   1.463724e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "7   1.405633e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "8   1.364427e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "9   1.315073e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "10  1.268189e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "11  1.232436e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "12  1.216791e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "13  1.204376e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "14  1.188522e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "15  1.174204e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "16  1.167980e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "17  1.166015e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "18  1.165803e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "19  1.165779e+07  <statsmodels.regression.linear_model.Regressio...   \n",
       "\n",
       "      test_error  \n",
       "1   1.798528e+07  \n",
       "2   1.534800e+07  \n",
       "3   1.529801e+07  \n",
       "4   1.656181e+07  \n",
       "5   1.585112e+07  \n",
       "6   1.685786e+07  \n",
       "7   1.541311e+07  \n",
       "8   1.734648e+07  \n",
       "9   1.771516e+07  \n",
       "10  1.655227e+07  \n",
       "11  1.718486e+07  \n",
       "12  1.771235e+07  \n",
       "13  1.711102e+07  \n",
       "14  1.723682e+07  \n",
       "15  1.730748e+07  \n",
       "16  1.721915e+07  \n",
       "17  1.734628e+07  \n",
       "18  1.740698e+07  \n",
       "19  1.739717e+07  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using train and test data\n",
    "fwd_train = forward(x_train, y_train)\n",
    "fwd_test = []\n",
    "for i in range(1, len(fwd_train) + 1):\n",
    "    model = fwd_train.loc[i]['model']\n",
    "    features = model.model.exog_names.copy()\n",
    "    features.remove('const')\n",
    "    eval_data = sm.add_constant(x_test[features])\n",
    "    residuals = y_test - fwd_train.loc[i]['model'].predict(eval_data)\n",
    "    error = (residuals * residuals).sum()\n",
    "    fwd_test.append(error)\n",
    "fwd_train.insert(2, 'test_error', fwd_test, True)\n",
    "# we can also perform cross validation in the forward function to make our stepwise better, but i'm not doing that\n",
    "# not hard, bue tedious\n",
    "fwd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b70384aa-a777-40a4-ad4a-8914ef17b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Salary   R-squared:                       0.338\n",
      "Model:                            OLS   Adj. R-squared:                  0.327\n",
      "Method:                 Least Squares   F-statistic:                     32.64\n",
      "Date:                Mon, 25 Jul 2022   Prob (F-statistic):           3.50e-12\n",
      "Time:                        20:23:14   Log-Likelihood:                -957.28\n",
      "No. Observations:                 131   AIC:                             1921.\n",
      "Df Residuals:                     128   BIC:                             1929.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         75.7880     75.416      1.005      0.317     -73.436     225.012\n",
      "CRuns          0.5419      0.090      5.989      0.000       0.363       0.721\n",
      "Runs           4.7788      1.243      3.846      0.000       2.320       7.237\n",
      "==============================================================================\n",
      "Omnibus:                       80.178   Durbin-Watson:                   1.902\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              469.859\n",
      "Skew:                           2.112   Prob(JB):                    9.36e-103\n",
      "Kurtosis:                      11.260   Cond. No.                     1.21e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.21e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "best_model = fwd_train.loc[fwd_train['test_error'].argmin()]\n",
    "print(best_model['model'].summary()) # 2 var model the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5716d9b-49d1-464d-94fb-1a39867f84ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
